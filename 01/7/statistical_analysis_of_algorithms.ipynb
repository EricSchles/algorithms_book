{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bbd75a",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Algorithms\n",
    "\n",
    "In the previous sections we saw how to prove or verify statements in general, how to disprove statements, how to test for correctness, and how to analyze our first algorithm.  The general technique of analyzing algorithms has historically been _very_ imprecise.  One of the intentions behind this text is to remedy that.  Instead of allowing for sloppy bounds where we don't care about the lower order terms or the \"constants\" associated with the running time of an algorithm, instead we will attempt to be somewhat precise here.\n",
    "\n",
    "Our running time analysis will not not represent a universal model of the running time of algorithms, but it will provide a _better_ mental model.  The way we will do this is through _statistical_ analysis of the running time of algorithms.  We will still use all the standard analysis tools that one would find in an algorithms book, however, once we have established our vague asymptotic model for the running time of the algorithm, we will attempt to make this _more_ precise by building a statistcal model of the algorithm, for this we will use the asymptotic bound as a guide, because it gives us a _general_ functional form for our running time.  But then we will _statistically learn_ the remaining components of the model for the running time of the algorithm.\n",
    "\n",
    "It is important to note, that our statistical model will still not be _exact_.  That is the particulars of the running time on a given machine, or in a given set up _may_ vary from the statistical analysis we do.  But that said, it should vary _less_.  In other words, we can get closer to a sense of how well exactly certain algorithms perform.  This will give us a rich sense of understanding, and allow us to make _informed_ choices about which algorithms to use.\n",
    "\n",
    "Of course, you can always _retest_ the analytic tools you'll be learning in this section against _any_ set up, meaning even if the statistical findings in this text are incongruent with your set up, you can simply redo them, and assess what will work best for _you_.  \n",
    "\n",
    "In this introductory chapter we will introduce one statistical algorithm for learning the functional form of the running time of a given algorithm - least squares.  For those of you who have taken a statistics class before, it is worth noting, this is _not_ the same thing as linear regression.  We will explicitly need different functional forms for _every_ algorithm we analyze.\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "In order to get as close as possible to statistical truth, we will also be running our experiments on as many different sets of hardware as possible.  While this isn't always easy to do, because who has 50 or 100 different machines lying around?  We can use docker to simulate these different hardware set ups.  We can also use different versions of Python to add another layer of statistical uncertainty.  It may be the case that certain operations a just a little slower on version A or version B of the language in specific cases, which could add just a bit of statistical noise that we can learn a richer representation on.\n",
    "\n",
    "## Least Squares Regression\n",
    "\n",
    "## A First Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef81fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
